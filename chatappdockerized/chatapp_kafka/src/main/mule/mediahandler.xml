<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:file="http://www.mulesoft.org/schema/mule/file" xmlns:kafka="http://www.mulesoft.org/schema/mule/kafka"
	xmlns:ee="http://www.mulesoft.org/schema/mule/ee/core"
	xmlns:http="http://www.mulesoft.org/schema/mule/http" xmlns:db="http://www.mulesoft.org/schema/mule/db" xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/db http://www.mulesoft.org/schema/mule/db/current/mule-db.xsd
http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
http://www.mulesoft.org/schema/mule/ee/core http://www.mulesoft.org/schema/mule/ee/core/current/mule-ee.xsd
http://www.mulesoft.org/schema/mule/kafka http://www.mulesoft.org/schema/mule/kafka/current/mule-kafka.xsd
http://www.mulesoft.org/schema/mule/file http://www.mulesoft.org/schema/mule/file/current/mule-file.xsd">
	<db:config name="Database_Config" doc:name="Database Config" doc:id="dbb57ee9-692f-45ca-9dc9-284aa030a6f8" >
		<db:generic-connection url="jdbc:postgresql://localhost:5432/chatapp" driverClassName="org.postgresql.Driver" user="postgres" password="root" />
	</db:config>
	<http:listener-config name="HTTP_Listener_config_87" doc:name="HTTP Listener config" doc:id="09d78e3e-7890-4d72-a452-076b1b365ba0" >
		<http:listener-connection host="0.0.0.0" port="8087" />
	</http:listener-config>
	<kafka:consumer-config name="MediaConsumer" doc:name="Apache Kafka Consumer configuration" doc:id="289984f0-9564-4964-aa60-a26a3db893ac" >
		<kafka:consumer-plaintext-connection >
			<kafka:bootstrap-servers >
				<kafka:bootstrap-server value="localhost:9092" />
			</kafka:bootstrap-servers>
			<kafka:topic-patterns >
				<kafka:topic-pattern value="MediaTopic0" />
			</kafka:topic-patterns>
		</kafka:consumer-plaintext-connection>
	</kafka:consumer-config>
	<kafka:consumer-config name="ReadConsumer" doc:name="Apache Kafka Consumer configuration" doc:id="7f2fcb05-8f25-476d-8a94-073b80c1cfbd" >
		<kafka:consumer-plaintext-connection >
			<kafka:bootstrap-servers >
				<kafka:bootstrap-server value="localhost:9092" />
			</kafka:bootstrap-servers>
			<kafka:topic-patterns >
				<kafka:topic-pattern value="fileread" />
			</kafka:topic-patterns>
		</kafka:consumer-plaintext-connection>
	</kafka:consumer-config>
	<kafka:producer-config name="Apache_Kafka_Producer_configuration" doc:name="Apache Kafka Producer configuration" doc:id="b3c4af29-b986-43bf-91a5-b024dc21a3b5" >
		<kafka:producer-plaintext-connection >
			<kafka:bootstrap-servers >
				<kafka:bootstrap-server value="localhost:9092" />
			</kafka:bootstrap-servers>
		</kafka:producer-plaintext-connection>
	</kafka:producer-config>
	<db:config name="Database_ConfigH2" doc:name="Database Config" doc:id="0460582a-1f6a-4fc9-a3ad-ad6f822fb758" >
		<db:generic-connection url="jdbc:h2:mem:testdb;DB_CLOSE_DELAY=-1" driverClassName="org.h2.Driver" user="sa" />
	</db:config>
	<http:listener-config name="HTTP_Listener_config_86" doc:name="HTTP Listener config" doc:id="32e14e02-8d77-45f5-b682-e148edf28888" >
		<http:listener-connection host="0.0.0.0" port="8086" />
	</http:listener-config>
	<kafka:consumer-config name="tempmsg0" doc:name="Apache Kafka Consumer configuration" doc:id="fc588539-1c4f-4de2-9201-ead3cf5dc180" >
		<kafka:consumer-plaintext-connection >
			<kafka:bootstrap-servers >
				<kafka:bootstrap-server value="localhost:9092" />
			</kafka:bootstrap-servers>
			<kafka:topic-patterns >
				<kafka:topic-pattern value="tempmsg0" />
			</kafka:topic-patterns>
		</kafka:consumer-plaintext-connection>
	</kafka:consumer-config>
	<kafka:producer-config name="retryQ" doc:name="Apache Kafka Producer configuration" doc:id="efe6ce16-219f-470f-8e21-4816245642d5" >
		<kafka:producer-plaintext-connection >
			<kafka:bootstrap-servers >
				<kafka:bootstrap-server value="localhost:9092" />
			</kafka:bootstrap-servers>
		</kafka:producer-plaintext-connection>
	</kafka:producer-config>
	<configuration doc:name="Configuration" doc:id="d39ef92f-7761-45e0-8d31-1a82c477b40d" defaultErrorHandler-ref="Error_Handler" />
	<flow name="InitializeTable" doc:id="06290756-b3e0-41ac-ac12-cc0c6c9be4ab" >
		<scheduler doc:name="Scheduler" doc:id="dbea50e2-d331-407f-b44d-e1503d91222f">
			<scheduling-strategy>
				<fixed-frequency frequency="1" timeUnit="DAYS"/>
			</scheduling-strategy>
		</scheduler>
		<db:execute-script doc:name="Initialize table Media" doc:id="91af5cfe-3cdc-41cd-820d-e4dc00c4cfb4" config-ref="Database_Config">
			<db:sql><![CDATA[CREATE TABLE IF NOT EXISTS media (
  fileid Varchar(255) PRIMARY KEY,
  filetype VARCHAR(255) NOT NULL,
  name VARCHAR(255) NOT NULL,
  chatid VARCHAR(255) NOT NULL,
  sender VARCHAR(255) NOT NULL,
  path TEXT NOT NULL,
  senttime TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  msgread BOOLEAN DEFAULT FALSE
);
]]></db:sql>
		</db:execute-script>
		<db:execute-script doc:name="initialize table delayed_acks" doc:id="a868b360-a46a-4de2-a55f-bb50c605e746" config-ref="Database_Config">
			<db:sql ><![CDATA[CREATE TABLE IF NOT EXISTS delayed_acks (
  id SMALLSERIAL PRIMARY KEY,
  name VARCHAR(255) NOT NULL
);]]></db:sql>
		</db:execute-script>
		<logger level="INFO" doc:name="Logger" doc:id="ae7604ca-20ca-4d9c-a03a-ffbb86e837cc" message='#["Table media (PostgreSQL) created"]' />
	</flow>
	<flow name="ListofIDs" doc:id="88d2434f-8927-403d-9974-445335e4bb6d" >
		<http:listener doc:name="Listener" doc:id="22917396-8c4a-4615-b249-61dab358f104" config-ref="HTTP_Listener_config_87" path="/media/idlist"/>
		<db:select doc:name="Fetch ID" doc:id="57520acf-6eae-4924-adb7-5a4fd829d762" config-ref="Database_Config">
			<db:sql ><![CDATA[Select fileid from media;]]></db:sql>
		</db:select>
		<ee:transform doc:name="Transform to List&lt;String&gt;" doc:id="fe1e4eb3-b8a3-49be-b229-810ae388227f">
			<ee:message>
				<ee:set-payload><![CDATA[%dw 2.0
output application/json
---
payload ]]></ee:set-payload>
			</ee:message>
		</ee:transform>
	</flow>
	<flow name="Insertdata" doc:id="d7e4dbaa-8df4-48ec-919b-9573442ca2d0" >
		<http:listener doc:name="Data insert API" doc:id="dc1843c0-bc95-4f9f-90fb-ea629b1739cb" config-ref="HTTP_Listener_config_87" path="/media/addmedia" allowedMethods="POST"/>
		<flow-ref doc:name="insert into table Media" doc:id="93e5e330-7e04-4fed-96ba-4ac06c8f4498" name="InsertDataQuery"/>
	</flow>
	<flow name="FindByChatID" doc:id="f0c20cd2-1261-40d6-b257-d1b8d518652f" >
		<http:listener doc:name="FindByChat" doc:id="2f0a176a-96b5-4756-ad64-90d3a528ba3f" config-ref="HTTP_Listener_config_87" path="/media/getchatmedia"/>
		<set-variable value="#[attributes.queryParams.chatid]" doc:name="Save Chatid" doc:id="66805642-1d51-46cf-8b49-33afac74ba8e" variableName="chatid" />
		<flow-ref doc:name="Subflow RetrieveByChat" doc:id="56bf2be2-fb11-4681-ba5a-3aa086e03694" name="RetrieveByChat"/>
	</flow>
	<flow name="GetFiledetails" doc:id="b32dd0ab-eece-4a7e-93a5-58016bab9241" >
		<http:listener doc:name="Listener" doc:id="ec0a0e9f-5ee8-4908-956a-0ecf89b185f4" config-ref="HTTP_Listener_config_87" path="/media/getfile"/>
		<db:select doc:name="Get File details" doc:id="a885af29-d6ba-4e59-980d-2e38f82f0cee" config-ref="Database_Config">
			<db:sql ><![CDATA[select * from media where fileid = :id ;]]></db:sql>
			<db:input-parameters ><![CDATA[#[id: attributes.queryParams.id]]]></db:input-parameters>
		</db:select>
		<ee:transform doc:name="Convert list&lt;media&gt; to media object" doc:id="8e7a5c0b-32b8-4e26-b898-2f0c33e1d05f" >
			<ee:message >
				<ee:set-payload ><![CDATA[%dw 2.0
output application/json
---
payload[0]]]></ee:set-payload>
			</ee:message>
		</ee:transform>
	</flow>
	<flow name="RetrieveByChat" doc:id="3b77ec9f-4254-4a42-9962-19142d08b990" >
		<db:select doc:name="Find all media in given chat" doc:id="670ca77d-0af1-4292-a353-8150d56b3118" config-ref="Database_Config">
			<db:sql ><![CDATA[Select * from media where chatid = :chatid ;]]></db:sql>
			<db:input-parameters ><![CDATA[#[chatid: vars.chatid default ""]]]></db:input-parameters>
		</db:select>
		<ee:transform doc:name="Convert to Json" doc:id="e5954dc5-9766-49bb-b1ce-21e0481e8c82" >
			<ee:message >
				<ee:set-payload ><![CDATA[%dw 2.0
output application/json
---
payload]]></ee:set-payload>
			</ee:message>
		</ee:transform>
	</flow>
	<flow name="MediaListener" doc:id="986187a9-fc3b-4245-9e45-112885a5108d" >
		<kafka:message-listener doc:name="Listen for Media Object" doc:id="035920c8-6474-49d9-95dc-e15cfb0b4a2c" config-ref="MediaConsumer"/>
		<ee:transform doc:name="Convert binary to Application/java" doc:id="3e7097bd-624a-4564-bfc3-9796c0c93e55" >
			<ee:message >
				<ee:set-payload ><![CDATA[%dw 2.0
output application/java
var body = read(payload, "application/json")
---
{
  id: body.fileid default null,
  filetype: body.filetype default null,
  name: body.name default null,
  path: body.path default null,
  chat: body.chatid default null,
  sender: body.sender default null,
  msgread: body.msgread default null,
  senttime:body.senttime default null
}
]]></ee:set-payload>
			</ee:message>
		</ee:transform>
		<flow-ref doc:name="Insert into table(InsertDataQuery)" doc:id="c62ddeb3-f8e1-4a00-8650-fb57204d9e69" name="InsertDataQuery"/>
	</flow>
	<flow name="mediahandlerFlow" doc:id="4b31fb98-24d4-4388-bb85-32095036a5d1" >
		<kafka:message-listener doc:name="Message listener" doc:id="5594ab9c-c0c3-4111-b72d-92ced16ae20a" config-ref="ReadConsumer"/>
		<ee:transform doc:name="Transform Message" doc:id="afc50066-76f9-4266-b579-635c2a6b269a" >
			<ee:message >
				<ee:set-payload ><![CDATA[%dw 2.0
output application/java
---
{
  id: payload[1 to -2]
}
]]></ee:set-payload>
			</ee:message>
		</ee:transform>
		<db:update doc:name="Update" doc:id="13aa2936-ff6b-4de9-a701-6b19e9933ed4" config-ref="Database_Config">
			<db:sql ><![CDATA[update media set msgread = true where fileid = :id]]></db:sql>
			<db:input-parameters ><![CDATA[#[{
  "id": payload.id
}]]]></db:input-parameters>
		</db:update>
		<logger level="INFO" doc:name="Logger" doc:id="f3f846d9-1b75-4478-a7ce-3ebe3b87e39d" message='#["set to read "]'/>
	</flow>
	<flow name="InsertDataQuery" doc:id="116b2e51-2f6b-4547-820e-396fc3d7d68e" >
		<set-variable value="#[{	fileid: payload.id,&#10;    name: payload.name,&#10;    filetype:payload.filetype,&#10;    sender:payload.sender,&#10;    chatid:payload.chat,&#10;    path:payload.path,&#10;    senttime:payload.senttime&#10;}]" doc:name="Set Variable" doc:id="ed4bd68d-ed43-4507-a6c9-150bf7e7bbd4" variableName="NewFile"/>
		<db:select doc:name="Check if duplicate exists" doc:id="61b04d18-bec1-4e00-b370-099cf6e4166d" config-ref="Database_Config">
			<db:sql ><![CDATA[SELECT 1 FROM media WHERE fileid = :id limit 1;]]></db:sql>
			<db:input-parameters ><![CDATA[#[id:vars.NewFile.fileid]]]></db:input-parameters>
		</db:select>
		<choice doc:name="Choice" doc:id="4d64fd38-55b6-4518-b6ba-5d3634e4e83d" >
			<when expression="isEmpty(payload)">
				<db:insert doc:name="Insert file" doc:id="5ec7988e-3509-4838-9f9e-47697272b882" config-ref="Database_Config">
			<db:sql><![CDATA[insert into media (fileid,filetype,name,path,chatid,sender,msgread,senttime) values(:id,:ftype,:name,:path,:chatid,:sender,:msgread,:senttime);]]></db:sql>
			<db:input-parameters><![CDATA[#[{
	id:vars.NewFile.fileid,
	ftype:vars.NewFile.filetype,
	name: vars.NewFile.name,
	path: vars.NewFile.path,
	chatid: vars.NewFile.chatid,
	sender: vars.NewFile.sender,
	msgread:false,
	senttime: vars.NewFile.senttime  default (now() as String { format: "yyyy-MM-dd HH:mm:ss.SSSSSS" })
}]]]></db:input-parameters>
			<db:auto-generated-keys-column-indexes />
		</db:insert>
				<kafka:publish doc:name="send ack back to spring " doc:id="001eda20-f56f-4f62-99d9-4d17090fa8de" config-ref="Apache_Kafka_Producer_configuration" topic="fileack">
			<kafka:message><![CDATA[#[vars.NewFile.name]]]></kafka:message>
		</kafka:publish>
				<logger level="INFO" doc:name="Logger" doc:id="0bab9b4e-0856-45ac-9da3-dde63ffb2bf1" message='#["Inserted into table : $(vars.NewFile.name) [$(vars.NewFile.fileid)] successfully"]' />
				<set-payload value='#["file of id [$(vars.NewFile.fileid)] inserted successfully"]' doc:name="Set Payload" doc:id="afc5f11f-af03-471b-b5c2-14712ed14267" />
			</when>
			<otherwise >
				<flow-ref doc:name="Handle duplicate" doc:id="b3a73e7d-4012-4518-aa2c-2d161dec5f2c" name="MediaDuplicateHandling"/>
			</otherwise>
		</choice>
	</flow>
	<flow name="MediaDuplicateHandling" doc:id="b879544d-2e84-4995-908c-cd3ae26967bb" >
		<db:select doc:name="Select" doc:id="9adc5630-beac-480c-8ca4-8e8d803940d2" config-ref="Database_Config" >
			<db:sql ><![CDATA[SELECT 1 FROM media WHERE fileid = :id AND path <> :path LIMIT 1;
]]></db:sql>
			<db:input-parameters ><![CDATA[#[{
id: vars.NewFile.fileid,
path: vars.NewFile.path
}]]]></db:input-parameters>
		</db:select>
		<choice doc:name="Choice" doc:id="c6e7c966-236b-4be0-b182-098a61f58a18" >
			<when expression="isEmpty(payload)" >
				<logger level="INFO" doc:name="Logger" doc:id="d0a45f54-9410-4056-9347-33388bd60f20" message='#["Found true duplicate [$(vars.NewFile.name)] . file ignored"]'/>
				<set-payload value='#["True duplicate found  "]' doc:name="Set Payload" doc:id="3f1df7b2-d0af-42aa-afd0-c87c2a6154ef" />
			</when>
			<otherwise >
				<kafka:publish doc:name="Send to RetryQ" doc:id="1ec65864-a458-4dd0-a900-6f55e1637d88" config-ref="retryQ" topic="newid" >
					<kafka:message ><![CDATA[#[vars.NewFile]]]></kafka:message>
				</kafka:publish>
				<logger level="INFO" doc:name="Logger" doc:id="e79e2c52-8001-4282-8955-465e8ae31da5" message='#["sent file $(vars.NewFile.name) to RetryQ"]'/>
				<set-payload value='#["error occured. transferring file to retryQ "]' doc:name="Set Payload" doc:id="d6e5ae25-e8a5-4ee5-86b8-fb0cf8612f25" />
			</otherwise>
		</choice>
	</flow>
	<flow name="HandleDelayedAcksPeriodically" doc:id="7be47b12-de4b-4740-8179-a81988fc4ed0">
		<scheduler doc:name="Scheduler" doc:id="5978b440-3000-496c-b41c-bcf71532533e">
			<scheduling-strategy>
				<fixed-frequency frequency="1" timeUnit="MINUTES" />
			</scheduling-strategy>
		</scheduler>
		<db:select doc:name="Select" doc:id="115159aa-e589-4d54-8028-c5a658cb2de2" config-ref="Database_Config">
			<db:sql><![CDATA[select * from delayed_acks ;]]></db:sql>
		</db:select>
		<foreach doc:name="For Each" doc:id="ba6a15ee-4054-4098-a98c-e2d059666ba0">
			<set-variable value="#[{&#10;	id: payload.id ,&#10;	name: payload.name &#10;}]" doc:name="Set Variable" doc:id="99e8603c-54c0-41db-b8ad-c3b44de29fad" variableName="currentFile" />
			<kafka:publish doc:name="send ack back to spring " doc:id="fea76f5c-9306-4123-89aa-912aebe2fac5" config-ref="Apache_Kafka_Producer_configuration" topic="fileack">
				<kafka:message><![CDATA[#[vars.currentFile.name]]]></kafka:message>
			</kafka:publish>
			<db:delete doc:name="Delete" doc:id="3ec0450d-477c-4abc-9766-db460580bafb" config-ref="Database_Config">
				<db:sql><![CDATA[delete from delayed_acks where id = :id ;]]></db:sql>
				<db:input-parameters><![CDATA[#[id : vars.currentFile.id]]]></db:input-parameters>
			</db:delete>
			<logger level="INFO" doc:name="Logger" doc:id="517cd592-62b3-41ea-83cc-2508a7f0f2c4" message='#["Ack for file : " ++ vars.currentFile.name ++" sent successfully"]' />
		</foreach>
		<error-handler>
			<on-error-continue enableNotifications="true" logException="true" doc:name="Log Errors" doc:id="e5c67602-dd66-4cda-ae5b-34fea84eb063" type="ANY">
				<logger level="ERROR" doc:name="Logger" doc:id="9705a111-470c-440f-ac98-7afa352bfe34" message='#["error in sending back the file ack"]' />
			</on-error-continue>
		</error-handler>
	</flow>
</mule>
